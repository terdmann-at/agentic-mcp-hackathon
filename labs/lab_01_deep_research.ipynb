{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0896f605",
   "metadata": {},
   "source": [
    "# Lab 1: Deep Research Agent with Multi-Agent System\n",
    "\n",
    "In this lab, we will build a \"Deep Research\" agent.\n",
    "This agent will take a topic, break it down into sub-topics, research them in parallel, and compile a final report.\n",
    "\n",
    "We will use `LangGraph` for orchestration and `Databricks` Model Serving for the LLM.\n",
    "\n",
    "## Structure\n",
    "1. **State Definition**: define the data structure that flows through the graph.\n",
    "2. **Nodes**: define the agents (Chief Editor, Researcher, Writer).\n",
    "3. **Graph**: connect the nodes.\n",
    "4. **Human-in-the-Loop**: add a planning phase with interrupts.\n",
    "\n",
    "First, let's install the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc816e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langgraph duckduckgo-search databricks-langchain pydantic typing_extensions\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46763c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import necessary libraries and initialize the LLM and Tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ab493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, TypedDict\n",
    "\n",
    "try:\n",
    "    from typing import NotRequired\n",
    "except ImportError:\n",
    "    from typing_extensions import NotRequired\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.types import Command, Send, interrupt\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Initialize Model\n",
    "from llm import model as llm\n",
    "\n",
    "# Initialize Search Tool\n",
    "search_tool = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47391cdc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Exercise 1: State Definition\n",
    "\n",
    "We need to define the state that holds our research data.\n",
    "\n",
    "The `ResearchState` should track:\n",
    "- `topic`: The user's original query.\n",
    "- `sub_topics`: A list of strings for parallel research.\n",
    "- `research_outputs`: A list of results from workers (this needs to be cumulative!).\n",
    "- `final_report`: The generated output.\n",
    "\n",
    "The `SubTaskState` is for individual workers and needs:\n",
    "- `topic`: The specific sub-topic to research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c47347",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Exercise 1: Define the State classes\n",
    "# <solution>\n",
    "class SubTaskState(TypedDict):\n",
    "    \"\"\"State for a single research worker agent.\"\"\"\n",
    "\n",
    "    topic: str\n",
    "    result: str\n",
    "\n",
    "\n",
    "class ResearchState(TypedDict):\n",
    "    \"\"\"Global state for the entire graph.\"\"\"\n",
    "\n",
    "    topic: str\n",
    "    sub_topics: List[str]\n",
    "    # Use operator.add to append new outputs to the list instead of overwriting\n",
    "    research_outputs: Annotated[List[str], operator.add]\n",
    "    final_report: str\n",
    "\n",
    "\n",
    "# </solution>\n",
    "\n",
    "\n",
    "class ResearchPlan(BaseModel):\n",
    "    \"\"\"Structured output for the Chief Editor.\"\"\"\n",
    "\n",
    "    sub_topics: List[str] = Field(\n",
    "        description=\"List of 3 distinct sub-topics to research in parallel\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb848896",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Exercise 2: Define Nodes\n",
    "\n",
    "We need three nodes:\n",
    "\n",
    "1. **Chief Editor**: breaks the topic into sub-topics.\n",
    "2. **Research Worker**: searches for information on a sub-topic.\n",
    "3. **Writer**: compiles the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda99c5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def chief_editor_node(state: ResearchState):\n",
    "    print(f\"--- [Chief Editor] Planning: {state['topic']} ---\")\n",
    "\n",
    "    # Exercise 2.1: Implement the Chief Editor\n",
    "    # Use the LLM to generate a 'ResearchPlan' from the topic.\n",
    "    # <solution>\n",
    "    planner = llm.with_structured_output(ResearchPlan)\n",
    "    prompt = (\n",
    "        f\"You are a Research Manager. Your goal is to break down the following research topic into 3 distinct, \"\n",
    "        f\"targeted sub-topics that will convince a search engine to reveal specific facts, numbers, or data points.\\n\\n\"\n",
    "        f\"Topic: {state['topic']}\\n\\n\"\n",
    "        f\"Return 3 distinct sub-topics.\"\n",
    "    )\n",
    "    plan = planner.invoke(prompt)\n",
    "\n",
    "    return {\"sub_topics\": plan.sub_topics}\n",
    "    # </solution>\n",
    "\n",
    "\n",
    "def research_worker_node(state: SubTaskState):\n",
    "    topic = state[\"topic\"]\n",
    "    print(f\"--- [Worker] Searching for: {topic} ---\")\n",
    "\n",
    "    # Exercise 2.2: Implement the Research Worker\n",
    "    # Use 'search_tool' to find info and return it in 'research_outputs'.\n",
    "    # <solution>\n",
    "    try:\n",
    "        res = search_tool.invoke(topic)\n",
    "    except Exception as e:\n",
    "        res = f\"Search failed: {e}\"\n",
    "\n",
    "    return {\"research_outputs\": [f\"## Subtopic: {topic}\\n{res}\\n\"]}\n",
    "    # </solution>\n",
    "\n",
    "\n",
    "def writer_node(state: ResearchState):\n",
    "    print(\"--- [Writer] Compiling Report ---\")\n",
    "\n",
    "    # Exercise 2.3: Implement the Writer\n",
    "    # Combine 'research_outputs' and ask the LLM to write a report.\n",
    "    # <solution>\n",
    "    combined_content = \"\\n\\n\".join(state[\"research_outputs\"])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a technical writer. Compile the following research notes into a comprehensive final report.\n",
    "\n",
    "    Topic: {state[\"topic\"]}\n",
    "\n",
    "    Research Notes:\n",
    "    {combined_content}\n",
    "\n",
    "    Instructions:\n",
    "    1. Synthesize the information into a clear, well-structured report.\n",
    "    2. End with a \"Final Answer:\" section.\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"final_report\": response.content}\n",
    "    # </solution>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d60a63a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Exercise 3: Graph Construction\n",
    "\n",
    "Now we wire them together.\n",
    "\n",
    "- **Start** -> **Chief Editor**\n",
    "- **Chief Editor** -> **Workers** (Conditional Edge using `Send`)\n",
    "- **Workers** -> **Writer**\n",
    "- **Writer** -> **End**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9030ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_subtopics(state: ResearchState):\n",
    "    # Exercise 3.1: Define the mapping logic\n",
    "    # Return a list of `Send` objects, one for each sub-topic.\n",
    "    # <solution>\n",
    "    return [\n",
    "        Send(\"research_worker\", {\"topic\": sub_topic})\n",
    "        for sub_topic in state[\"sub_topics\"]\n",
    "    ]\n",
    "    # </solution>\n",
    "\n",
    "\n",
    "# Exercise 3.2: Build the Graph\n",
    "# <solution>\n",
    "workflow = StateGraph(ResearchState)\n",
    "\n",
    "workflow.add_node(\"chief_editor\", chief_editor_node)\n",
    "workflow.add_node(\"research_worker\", research_worker_node)\n",
    "workflow.add_node(\"writer\", writer_node)\n",
    "\n",
    "workflow.add_edge(START, \"chief_editor\")\n",
    "workflow.add_conditional_edges(\"chief_editor\", map_subtopics, [\"research_worker\"])\n",
    "workflow.add_edge(\"research_worker\", \"writer\")\n",
    "workflow.add_edge(\"writer\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "# </solution>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38dce73",
   "metadata": {},
   "source": [
    "### Run the Graph (Basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = app.invoke({\"topic\": \"The future of Agentic AI\"})\n",
    "print(res[\"final_report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9da777",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Exercise 4: Human-in-the-Loop (Planning Phase)\n",
    "\n",
    "Real-world agents need supervision. Let's add a \"Planning Phase\" where the user can review and edit the sub-topics before research begins.\n",
    "\n",
    "We will implement a cycle in the graph:\n",
    "1. **Planner**: generates an initial plan (or regenerates based on feedback).\n",
    "2. **Reviewer**: interrupts execution to request user approval.\n",
    "3. **Conditional Edge**:\n",
    "   - If approved -> proceed to **Research Workers**.\n",
    "   - If rejected (with critique) -> loop back to **Planner**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c48cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new state for HITL\n",
    "class ResearchStateHITL(ResearchState):\n",
    "    critique: NotRequired[str]\n",
    "    approved: NotRequired[bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_node(state: ResearchStateHITL):\n",
    "    print(f\"--- [Planner] Planning: {state['topic']} ---\")\n",
    "\n",
    "    planner = llm.with_structured_output(ResearchPlan)\n",
    "\n",
    "    # If there is a critique, we are regenerating\n",
    "    if state.get(\"critique\"):\n",
    "        print(f\"--- [Planner] Regenerating with critique: {state.get('critique')} ---\")\n",
    "        prompt = f\"\"\"\n",
    "        Original Topic: {state[\"topic\"]}\n",
    "        Previous Plan: {state.get(\"sub_topics\")}\n",
    "        User Critique: {state.get(\"critique\")}\n",
    "\n",
    "        Generate a new plan with 3 distinct sub-topics that addresses the critique.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        # Initial plan\n",
    "        prompt = f\"Topic: {state['topic']}\\nReturn 3 distinct sub-topics.\"\n",
    "\n",
    "    plan = planner.invoke(prompt)\n",
    "    return {\"sub_topics\": plan.sub_topics, \"approved\": False}\n",
    "\n",
    "\n",
    "def reviewer_node(state: ResearchStateHITL):\n",
    "    # Exercise 4: Add the interrupt\n",
    "    # <solution>\n",
    "    # Interrupt and wait for feedback\n",
    "    # We allow the user to provide {\"approved\": True} or {\"critique\": \"...\"}\n",
    "    feedback = interrupt(\n",
    "        {\n",
    "            \"sub_topics\": state[\"sub_topics\"],\n",
    "            \"message\": \"Please review the research plan. Provide 'approved': True or 'critique': str.\",\n",
    "        }\n",
    "    )\n",
    "    # The feedback from resume is expected to update the state\n",
    "    return feedback\n",
    "    # </solution>\n",
    "\n",
    "\n",
    "def should_continue(state: ResearchStateHITL):\n",
    "    \"\"\"\n",
    "    Conditional edge logic:\n",
    "    - If approved -> Map to research workers\n",
    "    - If not approved -> Loop back to planner\n",
    "    \"\"\"\n",
    "    if state.get(\"approved\"):\n",
    "        # Map to workers\n",
    "        return [\n",
    "            Send(\"research_worker\", {\"topic\": sub_topic})\n",
    "            for sub_topic in state[\"sub_topics\"]\n",
    "        ]\n",
    "\n",
    "    # Loop back\n",
    "    return \"planner\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e226c7",
   "metadata": {},
   "source": [
    "### Re-build the Graph with HITL\n",
    "The logic is now explicit in the graph structure:\n",
    "`Planner` -> `Reviewer` -> (conditional) -> `Planner` or `Workers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfed510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# Re-define graph\n",
    "workflow_hitl = StateGraph(ResearchStateHITL)\n",
    "\n",
    "workflow_hitl.add_node(\"planner\", planner_node)\n",
    "workflow_hitl.add_node(\"reviewer\", reviewer_node)\n",
    "workflow_hitl.add_node(\"research_worker\", research_worker_node)\n",
    "workflow_hitl.add_node(\"writer\", writer_node)\n",
    "\n",
    "# Start -> Planner\n",
    "workflow_hitl.add_edge(START, \"planner\")\n",
    "\n",
    "# Planner -> Reviewer\n",
    "workflow_hitl.add_edge(\"planner\", \"reviewer\")\n",
    "\n",
    "# Reviewer -> Conditional (Planner or Workers)\n",
    "workflow_hitl.add_conditional_edges(\n",
    "    \"reviewer\", should_continue, [\"planner\", \"research_worker\"]\n",
    ")\n",
    "\n",
    "workflow_hitl.add_edge(\"research_worker\", \"writer\")\n",
    "workflow_hitl.add_edge(\"writer\", END)\n",
    "\n",
    "# Compile with checkpointer\n",
    "checkpointer = InMemorySaver()\n",
    "app_hitl = workflow_hitl.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1772d9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Run Interactive Session\n",
    "\n",
    "We need to handle the execution flow:\n",
    "1. Run until interrupt.\n",
    "2. Inspect payload.\n",
    "3. Resume with feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_research_interactive():\n",
    "    \"\"\"\n",
    "    Runs the research agent in an interactive loop.\n",
    "    Allows the user to review the plan and provide feedback.\n",
    "    \"\"\"\n",
    "    # 1. Setup\n",
    "    thread_id = \"research-thread-interact\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "    print(\"Welcome to the Deep Research Agent!\")\n",
    "    topic = input(\"Enter a research topic: \")\n",
    "\n",
    "    # We use a loop to handle the stream and inputs\n",
    "    # Initial input is the topic\n",
    "    current_input = {\"topic\": topic}\n",
    "    resume_command = None\n",
    "\n",
    "    while True:\n",
    "        # If we have a resume command (from the 2nd loop onwards), use it\n",
    "        if resume_command:\n",
    "            stream_input = resume_command\n",
    "        else:\n",
    "            stream_input = current_input\n",
    "\n",
    "        # Run the graph until it interrupts or finishes\n",
    "        # We need to stream to capture interrupts\n",
    "        events = app_hitl.stream(stream_input, config=config)\n",
    "\n",
    "        current_interrupt_value = None\n",
    "        final_report = None\n",
    "\n",
    "        print(\"\\n--- Agent Working ---\")\n",
    "        for event in events:\n",
    "            # Check for interrupt\n",
    "            if \"__interrupt__\" in event:\n",
    "                current_interrupt_value = event[\"__interrupt__\"][0].value\n",
    "\n",
    "            # Check for writer output (final step)\n",
    "            if \"writer\" in event:\n",
    "                final_report = event[\"writer\"].get(\"final_report\")\n",
    "\n",
    "        # A. If we got a final report, we are done\n",
    "        if final_report:\n",
    "            print(\"\\n\" + \"=\" * 40)\n",
    "            print(\"FINAL REPORT\")\n",
    "            print(\"=\" * 40)\n",
    "            print(final_report)\n",
    "            break\n",
    "\n",
    "        # B. If we hit an interrupt, ask for user feedback\n",
    "        if current_interrupt_value:\n",
    "            print(\"\\n\" + \"-\" * 40)\n",
    "            print(\"REVIEW PLAN\")\n",
    "            print(\"-\" * 40)\n",
    "            print(f\"Proposed Sub-topics: {current_interrupt_value['sub_topics']}\")\n",
    "\n",
    "            user_response = input(\n",
    "                \"\\nType 'ok' to approve, or enter your critique/changes: \"\n",
    "            ).strip()\n",
    "\n",
    "            if user_response.lower() in [\"ok\", \"yes\", \"approve\"]:\n",
    "                print(\"\\n> Approved. Proceeding to research...\")\n",
    "                resume_command = Command(resume={\"approved\": True})\n",
    "            else:\n",
    "                print(\"\\n> Critique received. Regenerating plan...\")\n",
    "                resume_command = Command(\n",
    "                    resume={\"approved\": False, \"critique\": user_response}\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the interactive session\n",
    "if __name__ == \"__main__\":\n",
    "    run_research_interactive()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
