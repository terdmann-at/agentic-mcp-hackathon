{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c30e81",
   "metadata": {},
   "source": [
    "# Lab 2: Multi-Agent System (MAS) with Progressive Disclosure\n",
    "\n",
    "In this lab, we build a Supervisor/Router agent that manages specialized sub-agents.\n",
    "\n",
    "The Main Agent does NOT see all tools at once (which can start overwhelm the context if we were to keep adding tools).\n",
    "Instead, it has two meta-tools:\n",
    "1. `search_tools(query)`: Finds relevant specialized agents.\n",
    "2. `call_tool(name, task)`: Delegates the task to a specific agent.\n",
    "\n",
    "**Sub-Agents**:\n",
    "1. **Searcher**: A ReAct agent with web search capabilities (from Exercise 4).\n",
    "2. **Coder**: A Code Execution agent (from Exercise 6).\n",
    "\n",
    "Finally, we evaluate this system against the GAIA benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50adece",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langgraph ddgs databricks-langchain smolagents pandas\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78457ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from ddgs import DDGS\n",
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Initialize generic model\n",
    "from llm import model as llm\n",
    "from smolagents import LocalPythonExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a6207",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 1. Define Sub-Agents (The Specialists)\n",
    "\n",
    "These are \"factories\" that create a fresh agent instance when called.\n",
    "This ensures isolation of state between calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa5bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def web_search(query: str, max_results: int = 5):\n",
    "    \"\"\"Run a web search\"\"\"\n",
    "    return str(DDGS().text(query, max_results=max_results))\n",
    "\n",
    "\n",
    "def make_search_agent():\n",
    "    \"\"\"Creates a ReAct agent equipped with Web Search.\"\"\"\n",
    "    # Exercise 2.1: Create a ReAct agent using `create_agent`\n",
    "    # Hint: pass the llm and the list of tools ([web_search])\n",
    "    # <solution>\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "    # </solution>\n",
    "\n",
    "\n",
    "@tool\n",
    "def exec_python(code: str):\n",
    "    \"\"\"\n",
    "    Evaluate python code.\n",
    "    \"\"\"\n",
    "    # Initialize a fresh executor for safety/isolation per call if needed,\n",
    "    # but here we use a shared one for the session or per-turn.\n",
    "    # For a true tool usage, we might want a new interpreter each time or keep state.\n",
    "    # Let's create a fresh one to be safe.\n",
    "    interpreter = LocalPythonExecutor(\n",
    "        additional_authorized_imports=[\n",
    "            \"pandas\",\n",
    "            \"matplotlib\",\n",
    "            \"sklearn\",\n",
    "            \"numpy\",\n",
    "            \"datetime\",\n",
    "        ],\n",
    "    )\n",
    "    # We can inject some default data if needed, but we'll start empty.\n",
    "    try:\n",
    "        output = interpreter(code)\n",
    "        return f\"Stdout:\\n{str(interpreter.state['_print_outputs'])}\\nOutput: {output}\"\n",
    "    except Exception as e:\n",
    "        return f\"Execution Error: {e}\"\n",
    "\n",
    "\n",
    "def make_coding_agent():\n",
    "    \"\"\"Creates a generic agent equipped with a Python Code Executor.\"\"\"\n",
    "    # Exercise 2.2: Create a coding agent\n",
    "    # Hint: Use `create_agent` with [exec_python] tool\n",
    "    # <solution>\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "    # </solution>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2fa3c",
   "metadata": {},
   "source": [
    "## 2. Tool Registry & Discovery Mechanism\n",
    "\n",
    "We define the \"Registry\" of available skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251fa96",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "TOOL_REGISTRY = {\n",
    "    \"SearchAgent\": {\n",
    "        \"description\": \"Capable of searching the live internet for up-to-date facts, news, and general knowledge.\",\n",
    "        \"factory\": make_search_agent,\n",
    "    },\n",
    "    \"CodingAgent\": {\n",
    "        \"description\": \"Capable of writing and executing Python code to solve math problems, data analysis, or algorithmic tasks.\",\n",
    "        \"factory\": make_coding_agent,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_tools(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for available tools/agents relevant to the query.\n",
    "    Returns a list of tool names and their descriptions.\n",
    "    \"\"\"\n",
    "    print(f\"--- [Main] Searching tools for: {query} ---\")\n",
    "    results = []\n",
    "    # Exercise 2.3: Implement Tool Discovery\n",
    "    # Iterate over TOOL_REGISTRY and format the name and description for the LLM.\n",
    "    # <solution>\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "    # </solution>\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "\n",
    "@tool\n",
    "def call_tool(tool_name: str, task: str) -> str:\n",
    "    \"\"\"\n",
    "    Delegates a specific task to a named tool/agent.\n",
    "    \"\"\"\n",
    "    print(f\"--- [Main] Calling {tool_name} with task: {task[:50]}... ---\")\n",
    "\n",
    "    entry = TOOL_REGISTRY.get(tool_name)\n",
    "    if not entry:\n",
    "        return f\"Error: Tool '{tool_name}' not found. Please use 'search_tools' to see available tools.\"\n",
    "\n",
    "    # Exercise 2.4: Implement Tool Delegation\n",
    "    # 1. Instantiate the agent using the factory\n",
    "    # 2. Invoke the agent with the task (wrapped in HumanMessage)\n",
    "    # 3. Return the content of the last message\n",
    "    # <solution>\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "    # </solution>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a548d44",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 3. Main Agent (The Supervisor)\n",
    "\n",
    "The Main Agent only has access to `search_tools` and `call_tool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_main_agent():\n",
    "    system_prompt = (\n",
    "        \"You are a helpful Assistant and Project Manager. \"\n",
    "        \"You do not have direct abilities to search or code. \"\n",
    "        \"Instead, you must:\"\n",
    "        \"\\n1. Analyze the user's request.\"\n",
    "        \"\\n2. Use 'search_tools' to find capable sub-agents.\"\n",
    "        \"\\n3. Use 'call_tool' to delegate work to them.\"\n",
    "        \"\\n4. Synthesize their outputs into a final answer.\"\n",
    "        \"\\n\\nAlways verify which tool matches the needs before calling it.\"\n",
    "    )\n",
    "\n",
    "    # Exercise 2.5: Create the Main Agent\n",
    "    # Give it access to `search_tools` and `call_tool`.\n",
    "    # <solution>\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "    # </solution>\n",
    "\n",
    "\n",
    "main_agent = make_main_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffdb41b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 4. Evaluation Loop (GAIA Benchmark)\n",
    "\n",
    "We evaluate the system on the GAIA validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf5015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gaia_eval():\n",
    "    csv_path = \"gaia_validation_level1.csv\"  # Ensure this file exists in CWD\n",
    "    try:\n",
    "        # Load first 2 examples for quick testing\n",
    "        df = pd.read_csv(csv_path)[:2]\n",
    "        print(f\"Loaded {len(df)} tasks for evaluation.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Dataset not found at {csv_path}. Please generate it first.\")\n",
    "        return\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Simple Judge Logic (Internal function to avoid external dependency for now)\n",
    "    def query_judge(question, predicted, truth):\n",
    "        prompt = f\"\"\"\n",
    "        [QUESTION]: {question}\n",
    "        [GROUND TRUTH]: {truth}\n",
    "        [PREDICTED]: {predicted}\n",
    "\n",
    "        Compare Predicted to Ground Truth. Score 1 (Wrong) to 10 (Perfect).\n",
    "        Format: SCORE: <int>\n",
    "        \"\"\"\n",
    "        try:\n",
    "            res = llm.invoke(prompt).content\n",
    "            match = re.search(r\"SCORE:\\s*(\\d+)\", res)\n",
    "            return int(match.group(1)) if match else 0\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        question = row[\"Question\"]\n",
    "        truth = row[\"Final answer\"]\n",
    "\n",
    "        print(f\"\\nProcessing Task {idx + 1}: {question}\")\n",
    "\n",
    "        # Exercise 2.6: Invoke the Main Agent\n",
    "        # Invoke `main_agent` with the question and get the final response.\n",
    "        # <solution>\n",
    "        # TODO: Implement this\n",
    "        pass\n",
    "        # </solution>\n",
    "\n",
    "        print(f\"[Result]: {predicted[:100]}...\")\n",
    "\n",
    "        score = query_judge(question, predicted, truth)\n",
    "        print(f\"[Score]: {score}\")\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"question\": question,\n",
    "                \"truth\": truth,\n",
    "                \"predicted\": predicted,\n",
    "                \"score\": score,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(\"\\n=== Final Results ===\")\n",
    "    print(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc2cc7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Try the system out\n",
    "question = (\n",
    "    \"What is the 10th Fibonacci number (where F1=0, F2=1) multiplied by \"\n",
    "    \"the square root of the birth year of the current Microsoft CEO? \"\n",
    "    \"Delegate web search and coding tasks using appropriate tools. \"\n",
    "    \"Round the final answer to 2 decimal places.\"\n",
    ")\n",
    "res = main_agent.invoke({\"messages\": [HumanMessage(question)]})\n",
    "print(f\"Agent: {res['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd5f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2.7 (Bonus): Try to optimize the agent to do well on the eval.\n",
    "#\n",
    "# run_gaia_eval()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
