{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea57a7c6",
   "metadata": {},
   "source": [
    "# Exercise 7: Coding Agent - \"Plan in Code\"\n",
    "\n",
    "In this exercise, we implement an agent that performs \"Deep Research\" by generating and executing Python code.\n",
    "Instead of standard tool calling (JSON), the agent writes a Python script that orchestrates tool usage.\n",
    "\n",
    "This pattern allows for complex logic, loops, and variable handling directly in the plan.\n",
    "\n",
    "We will inject two custom tools into the Python execution environment:\n",
    "1. `search(query)`: Performs a web search.\n",
    "2. `synthesize(data)`: Uses the LLM to summarize/synthesize findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5375f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain smolagents databricks-langchain ddgs langchain-community\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ddgs import DDGS\n",
    "from langchain.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Initialize Model\n",
    "from llm import model as llm\n",
    "from smolagents import LocalPythonExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec527139",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## 1. Define Tools as Python Functions\n",
    "\n",
    "These functions will be \"exposed\" to the `LocalPythonExecutor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075614ee",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the web for the given query.\n",
    "    Returns the search results as a string.\n",
    "    \"\"\"\n",
    "    print(f\"--> [Tool: Search] '{query}'\")\n",
    "    try:\n",
    "        results = DDGS().text(query, max_results=3)\n",
    "        return str(results)\n",
    "    except Exception as e:\n",
    "        return f\"Search Error: {e}\"\n",
    "\n",
    "\n",
    "# Exercise 7.1: Define the `synthesize` tool\n",
    "# This tool should take a string (content) and use the LLM to summarize/synthesize it.\n",
    "# We want the agent to use this to process search results.\n",
    "# Hint: Use `llm.invoke` with a prompt.\n",
    "# <solution>\n",
    "def synthesize(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Synthesizes/Summarizes the provided content using an LLM.\n",
    "    \"\"\"\n",
    "    print(f\"--> [Tool: Synthesize] Processing {len(content)} chars...\")\n",
    "    prompt = f\"Summarize and synthesize the following information:\\n\\n{content}\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "\n",
    "# </solution>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079da082",
   "metadata": {},
   "source": [
    "## 2. Setup Code Executor\n",
    "\n",
    "We configure `LocalPythonExecutor` and inject our tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 7.2: Initialize LocalPythonExecutor\n",
    "# Inject `search` and `synthesize` into the environment.\n",
    "# Hint: Inject tools into `interpreter.state`.\n",
    "# <solution>\n",
    "interpreter = LocalPythonExecutor(additional_authorized_imports=[\"datetime\", \"math\"])\n",
    "# Inject our custom functions into the global scope of the interpreter\n",
    "interpreter.state[\"search\"] = search\n",
    "interpreter.state[\"synthesize\"] = synthesize\n",
    "# </solution>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed3b14c",
   "metadata": {},
   "source": [
    "## 3. Define the Agent Logic\n",
    "\n",
    "The agent loop:\n",
    "1. Receive User goal.\n",
    "2. Generate Python code to solve it (using `search` and `synthesize`).\n",
    "3. Execute code.\n",
    "4. Return result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e514c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert Python programmer and researcher.\n",
    "Your goal is to answer the user's question by WRITING A PYTHON SCRIPT.\n",
    "\n",
    "You have access to the following built-in functions:\n",
    "- `search(query: str) -> str`: Search the web.\n",
    "- `synthesize(content: str) -> str`: Summarize information.\n",
    "- `print(obj)`: Print to stdout (visible to you).\n",
    "\n",
    "Internal Logic/Plan:\n",
    "1. Break down the user's request.\n",
    "2. Search for necessary information (you can call `search` multiple times).\n",
    "3. Synthesize the findings if needed.\n",
    "4. Print the final answer clearly.\n",
    "\n",
    "Output ONLY the Python code. Do not wrap in markdown blocks if possible, or I will strip them.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_coding_agent(user_query: str):\n",
    "    print(f\"--- [Agent] Goal: {user_query} ---\")\n",
    "\n",
    "    messages = [SystemMessage(content=SYSTEM_PROMPT), HumanMessage(content=user_query)]\n",
    "\n",
    "    # Exercise 7.3: Implement the generation and execution\n",
    "    # 1. Invoke LLM to get code.\n",
    "    # 2. Clean code (strip ```python ... ```).\n",
    "    # 3. Execute using `interpreter`.\n",
    "    # <solution>\n",
    "    # 1. Generate Code\n",
    "    response = llm.invoke(messages)\n",
    "    code = response.content\n",
    "\n",
    "    # 2. Clean Code\n",
    "    if \"```python\" in code:\n",
    "        code = code.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    elif \"```\" in code:\n",
    "        code = code.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "    print(f\"--- [Agent] Generated Code ---\\n{code}\\n----------------------------\")\n",
    "\n",
    "    # 3. Execute\n",
    "    try:\n",
    "        # LocalPythonExecutor call returns the value of the last expression or print capture\n",
    "        # smolagents uses `interpreter(...)`\n",
    "        result = interpreter(code)\n",
    "\n",
    "        # We also capture stdout usually, but let's see what it returns\n",
    "        # Combine return value and any captured prints\n",
    "        captured_stdout = interpreter.state.get(\"_print_outputs\", \"\")\n",
    "\n",
    "        final_output = f\"Stdout:\\n{captured_stdout}\\n\\nReturn Value:\\n{result}\"\n",
    "        return final_output\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Execution Code Error: {e}\"\n",
    "    # </solution>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5c76bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agent\n",
    "if __name__ == \"__main__\":\n",
    "    query = (\n",
    "        \"What is the 10th Fibonacci number (where F1=0, F2=1) multiplied by \"\n",
    "        \"the square root of the birth year of the current Microsoft CEO? \"\n",
    "        \"Use the 'delegate_code_task' tool to perform the calculation using Python. \"\n",
    "        \"Round the final answer to 2 decimal places.\"\n",
    "    )\n",
    "    result = run_coding_agent(query)\n",
    "    print(f\"\\n=== FINAL OUTPUT ===\\n{result}\")\n",
    "    # should be 2439.55"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
