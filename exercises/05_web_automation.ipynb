{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e2d0c6",
   "metadata": {},
   "source": [
    "# Exercise 5: Web Automation & Vision Agent\n",
    "\n",
    "Goal: Build a visual web browsing agent using Helium and LangGraph.\n",
    "\n",
    "This agent will be able to navigate the web, see screenshots, and interact with elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38413fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install databricks-langchain langgraph helium\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1aaca5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from helium import click, get_driver, go_to, start_chrome, write\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2aef15",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Set HEADLESS=True for running in generalized environments\n",
    "# On Databricks, this should likely be True unless you have a display forwarding setup\n",
    "HEADLESS = os.getenv(\"HEADLESS\", \"True\").lower() == \"true\"\n",
    "\n",
    "\n",
    "# Setup simplified Helium Navigator\n",
    "class HeliumNavigator:\n",
    "    _instance = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self._is_initialized = False\n",
    "\n",
    "    @classmethod\n",
    "    def get_instance(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = HeliumNavigator()\n",
    "        return cls._instance\n",
    "\n",
    "    def initialize(self):\n",
    "        if not self._is_initialized:\n",
    "            # We use headless=False so you can see what's happening!\n",
    "            # Use headless=True in Codespaces (no display)\n",
    "            start_chrome(headless=HEADLESS)\n",
    "            self._is_initialized = True\n",
    "\n",
    "    def get_screenshot_b64(self) -> str:\n",
    "        self.initialize()\n",
    "        driver = get_driver()\n",
    "\n",
    "        # In HEADLESS mode, save the screenshot to disk so the user can see it\n",
    "        # In a notebook, we could also display it inline, but saving to disk is safe\n",
    "        if HEADLESS:\n",
    "            os.makedirs(\"screenshots\", exist_ok=True)\n",
    "            timestamp = int(time.time())\n",
    "            filename = f\"screenshots/screenshot_{timestamp}.png\"\n",
    "            driver.save_screenshot(filename)\n",
    "            print(f\"\\n[Headless Mode] Saved screenshot to {filename}\")\n",
    "\n",
    "        return driver.get_screenshot_as_base64()\n",
    "\n",
    "    def navigate(self, url: str) -> str:\n",
    "        self.initialize()\n",
    "        try:\n",
    "            go_to(url)\n",
    "            time.sleep(2)\n",
    "            return f\"Navigated to {url}.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error navigating to {url}: {e}\"\n",
    "\n",
    "    def click_element(self, target: str) -> str:\n",
    "        self.initialize()\n",
    "        try:\n",
    "            click(target)\n",
    "            time.sleep(1)\n",
    "            return f\"Clicked '{target}'.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error clicking '{target}': {e}\"\n",
    "\n",
    "    def type_text(self, text: str) -> str:\n",
    "        self.initialize()\n",
    "        try:\n",
    "            write(text)\n",
    "            time.sleep(1)\n",
    "            return f\"Typed '{text}'.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error typing '{text}': {e}\"\n",
    "\n",
    "\n",
    "navigator = HeliumNavigator.get_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c84b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.1: Define Tools\n",
    "# We will wrap the navigator methods into tools.\n",
    "# Note: get_screenshot returns the base64 string directly for the agent to \"see\".\n",
    "\n",
    "\n",
    "@tool\n",
    "def navigate(url: str) -> str:\n",
    "    \"\"\"Navigate the browser to a specific URL.\"\"\"\n",
    "    return navigator.navigate(url)\n",
    "\n",
    "\n",
    "@tool\n",
    "def click_element(target: str) -> str:\n",
    "    \"\"\"Click an element. 'target' can be the visible text on the button/link.\"\"\"\n",
    "    return navigator.click_element(target)\n",
    "\n",
    "\n",
    "@tool\n",
    "def type_text(text: str) -> str:\n",
    "    \"\"\"Type text into the focused element.\"\"\"\n",
    "    return navigator.type_text(text)\n",
    "\n",
    "\n",
    "# <solution>\n",
    "@tool\n",
    "def get_screenshot() -> str:\n",
    "    \"\"\"Get the current page screenshot as a base64 string.\"\"\"\n",
    "    return navigator.get_screenshot_b64()\n",
    "\n",
    "\n",
    "# </solution>\n",
    "\n",
    "\n",
    "# Exercise 5.5: Handling Loop Termination (Didactic)\n",
    "#\n",
    "# Logic: The agent loop continues as long as the model calls a tool.\n",
    "# If the model emits plain text, the loop terminates (see `should_continue` below).\n",
    "#\n",
    "# PROBLEM: The model might see the screenshot and just \"think\" or \"describe\" what it sees\n",
    "# in plain text without calling a navigation tool. This causes the loop to end prematurely\n",
    "# before the task is actually done.\n",
    "\n",
    "# <solution>\n",
    "@tool\n",
    "def think(thought: str) -> str:\n",
    "    \"\"\"Use this tool to think, plan, or analyze data/screenshots.\n",
    "    Do NOT use this tool to communicate with the user.\n",
    "    \"\"\"\n",
    "    return thought\n",
    "\n",
    "\n",
    "# </solution>\n",
    "\n",
    "\n",
    "tools = [navigate, click_element, type_text, get_screenshot, think]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "model = ChatDatabricks(endpoint=\"databricks-claude-sonnet-4-5\")\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Definition\n",
    "class VisualState(TypedDict):\n",
    "    # We store the conversation history\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "\n",
    "# Exercise 5.2: Define Custom Tool Node\n",
    "# This node executes tools. If the tool is `get_screenshot`, it handles the base64 output\n",
    "# by creating a multimodal ToolMessage.\n",
    "\n",
    "\n",
    "def tool_node(state: VisualState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    results = []\n",
    "\n",
    "    for tool_call in last_message.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        call_id = tool_call[\"id\"]\n",
    "\n",
    "        selected_tool = tools_by_name[tool_name]\n",
    "\n",
    "        # Invoke the tool\n",
    "        output = selected_tool.invoke(tool_args)\n",
    "\n",
    "        # <solution>\n",
    "        # Special handling for screenshot to make it visible to the model\n",
    "        if tool_name == \"get_screenshot\":\n",
    "            # output is the base64 string\n",
    "            content = [\n",
    "                {\"type\": \"text\", \"text\": \"Here is the screenshot of the current page.\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:image/png;base64,{output}\"},\n",
    "                },\n",
    "            ]\n",
    "            results.append(ToolMessage(content=content, tool_call_id=call_id))\n",
    "        else:\n",
    "            # Standard text output\n",
    "            results.append(ToolMessage(content=str(output), tool_call_id=call_id))\n",
    "        # </solution>\n",
    "\n",
    "    return {\"messages\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45237ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Node\n",
    "def agent_node(state: VisualState):\n",
    "    # The model deals with the history of messages which now includes images\n",
    "    messages = state[\"messages\"]\n",
    "    # We add a system prompt to ensure the model knows it can see\n",
    "    if not isinstance(messages[0], SystemMessage):\n",
    "        system = SystemMessage(\n",
    "            \"You are a visual web browsing agent. \"\n",
    "            \"For any internal analysis, planning, or screenshot interpretation, you MUST use the `think` tool. \"\n",
    "            \"Only output plain text when you are providing the FINAL ANSWER to the user. \"\n",
    "            \"When you receive a screenshot, verify strictly if you have the answer. \"\n",
    "            \"Do not ask if you should describe it; just do the analysis with the `think` tool.\"\n",
    "        )\n",
    "        messages = [system] + messages\n",
    "\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def should_continue(state: VisualState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b9f50",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Exercise 5.3: Build the Graph\n",
    "# Define the nodes and edges for the ReAct architecture.\n",
    "\n",
    "# <solution>\n",
    "workflow = StateGraph(VisualState)\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile()\n",
    "# </solution>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5383f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5.4: Run the Agent\n",
    "# Instruct the agent to perform a visual task.\n",
    "\n",
    "# query = \"Go to https://www.daytonartinstitute.org/exhibits/janet-fish/ and look at the painting 'Embroidery from Uzbekistan'. List what fruits are depicted in it. Make sure to scroll down to have the complete image captured\"\n",
    "query = \"I'm trying to find how hard I have to work to get a repo in github.com/trending. Can you navigate to the profile for the top author of the top trending repo, and give me their total number of commits over the last year?\"\n",
    "print(f\"User: {query}\")\n",
    "\n",
    "# <solution>\n",
    "# Note: We stream to see the steps\n",
    "inputs = {\"messages\": [HumanMessage(content=query)]}\n",
    "for event in app.stream(inputs, stream_mode=\"values\", config={\"recursion_limit\": 50}):\n",
    "    message = event[\"messages\"][-1]\n",
    "    if isinstance(message, AIMessage):\n",
    "        print(f\"AI: {message.content}\")\n",
    "        if message.tool_calls:\n",
    "            print(f\"   Tools: {message.tool_calls}\")\n",
    "    elif isinstance(message, ToolMessage):\n",
    "        print(f\"Tool ({message.name}): [Output received]\")\n",
    "# </solution>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
