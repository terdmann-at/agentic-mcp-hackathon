{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c21e4e",
   "metadata": {},
   "source": [
    "# Exercise 3: Tool Calling\n",
    "\n",
    "Goal: Use LangChain to call a custom tool and handle the response.\n",
    "Expected time: 10 min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install databricks-langchain langchain-core\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9730ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatDatabricks(endpoint=\"databricks-claude-sonnet-4-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.1: Define a tool using the decorator\n",
    "# <solution>\n",
    "@tool\n",
    "# </solution>\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the weather for a location.\"\"\"\n",
    "    if \"Berlin\" in location:\n",
    "        return \"Cloudy, 15C\"\n",
    "    return \"Sunny, 25C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af07ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    tools = [get_weather]\n",
    "    tools_by_name = {t.name: t for t in tools}\n",
    "\n",
    "    # Exercise 3.2: Bind the tool to the model\n",
    "    # <solution>\n",
    "    model_with_tools = model.bind_tools(tools)\n",
    "    # </solution>\n",
    "\n",
    "    query = \"What is the weather in Berlin?\"\n",
    "    messages = [HumanMessage(content=query)]\n",
    "\n",
    "    # Exercise 3.3: Invoke the model to get the tool call\n",
    "    # <solution>\n",
    "    ai_msg = model_with_tools.invoke(messages)\n",
    "    # </solution>\n",
    "    messages.append(ai_msg)\n",
    "    print(f\"AI Call: {ai_msg.tool_calls}\")\n",
    "\n",
    "    # Exercise 3.4: Execute tool calls manually and append results\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        selected_tool = tools_by_name[tool_call[\"name\"]]\n",
    "        \n",
    "        # Invoke the selected tool\n",
    "        # <solution>\n",
    "        tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "        # </solution>\n",
    "        print(f\"Tool Output: {tool_output}\")\n",
    "\n",
    "        messages.append(ToolMessage(content=tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "    # Exercise 3.5: Get the final response\n",
    "    # <solution>\n",
    "    final_response = model_with_tools.invoke(messages)\n",
    "    # </solution>\n",
    "    print(f\"Final Answer: {final_response.content}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
