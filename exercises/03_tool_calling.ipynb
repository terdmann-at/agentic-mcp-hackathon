{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c2f3da1",
   "metadata": {},
   "source": [
    "# Exercise 3: Tool Calling\n",
    "\n",
    "Goal: Use LangChain to call a custom tool and handle the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be8515",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain databricks-langchain\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6703f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage, ToolMessage\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b69c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f976b41",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Tools\n",
    "\n",
    "Tools are simply python functions that are wrapped by the `@tool` decorator.\n",
    "\n",
    "The decorator takes care of translating the docstring and the types of the inputs into instructions\n",
    "for the LLM when given the tool. The LLM does not call the function itself, instead it responds\n",
    "with a json structure representing a call to the function, which we will"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c2a437",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Exercise 3.1: Define a tool using the decorator. The tool should return the weather for a location.\n",
    "# You can simply return a string for now (e.g. \"Cloudy, 15C\").\n",
    "# <solution>\n",
    "# TODO: Implement this\n",
    "pass\n",
    "# </solution>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db50703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    tools = [get_weather]\n",
    "    tools_by_name = {t.name: t for t in tools}\n",
    "\n",
    "    # Exercise 3.2: Bind the tool to the model. Use the .bind_tools method.\n",
    "    # <solution>\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "    # </solution>\n",
    "\n",
    "    query = \"What is the weather in Berlin?\"\n",
    "    messages = [HumanMessage(content=query)]\n",
    "\n",
    "    # Exercise 3.3: Invoke the model to get the tool call\n",
    "    # <solution>\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "    # </solution>\n",
    "    messages.append(ai_msg)\n",
    "    print(f\"AI Call: {ai_msg.tool_calls}\")\n",
    "\n",
    "    # Exercise 3.4: Execute tool calls manually and append results\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        selected_tool = tools_by_name[tool_call[\"name\"]]\n",
    "\n",
    "        # Invoke the selected tool\n",
    "        # <solution>\n",
    "        # TODO: Implement this\n",
    "        pass\n",
    "        # </solution>\n",
    "        print(f\"Tool Output: {tool_output}\")\n",
    "\n",
    "        messages.append(ToolMessage(content=tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "    # Exercise 3.5: Get the final response\n",
    "    # <solution>\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "    # </solution>\n",
    "    print(f\"Final Answer: {final_response.content}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
