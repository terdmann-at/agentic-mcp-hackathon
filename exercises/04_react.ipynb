{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d31ab1",
   "metadata": {},
   "source": [
    "# Exercise 4: ReAct Agent\n",
    "\n",
    "Goal: Build a ReAct agent from scratch using LangGraph.\n",
    "Expected time: 15 min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c925d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install databricks-langchain langchain-community ddgs langgraph\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Literal\n",
    "\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain.messages import AnyMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain.tools import BaseTool, tool\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from typing_extensions import Annotated, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dfe874",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatDatabricks(endpoint=\"databricks-claude-sonnet-4-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply `a` and `b`.Args: a: First int, b: Second int\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds `a` and `b`.Args: a: First int, b: Second int\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "# Exercise 4.1: Define the divide tool\n",
    "# Hint: Use the @tool decorator. The function should take two ints and return a float.\n",
    "# <solution>\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide `a` and `b`.Args: a: First int, b: Second int\"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "# </solution>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ee7cba",
   "metadata": {},
   "source": [
    "## Web search\n",
    "\n",
    "Let's also try adding another interesting tool: web search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa57bae5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# the agent will have these tools\n",
    "tools = [add, multiply, divide]\n",
    "\n",
    "\n",
    "def build_agent(tools: list[BaseTool]):\n",
    "    tools_by_name = {tool.name: tool for tool in tools}\n",
    "    model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "    # State\n",
    "    class MessagesState(TypedDict):\n",
    "        messages: Annotated[list[AnyMessage], operator.add]\n",
    "        llm_calls: int\n",
    "\n",
    "    # Nodes\n",
    "    def llm_call(state: dict):\n",
    "        \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                model_with_tools.invoke(\n",
    "                    [\n",
    "                        SystemMessage(\n",
    "                            content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "                        )\n",
    "                    ]\n",
    "                    + state[\"messages\"]\n",
    "                )\n",
    "            ],\n",
    "            \"llm_calls\": state.get(\"llm_calls\", 0) + 1,\n",
    "        }\n",
    "\n",
    "    def tool_node(state: dict):\n",
    "        \"\"\"Performs the tool call\"\"\"\n",
    "        result = []\n",
    "        for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "            # Exercise 4.2: Handle the tool call. That is, call the function with the arguments\n",
    "            # requested by the LLM and add the result (as a `ToolMessage`) to the conversation history.\n",
    "            # <solution>\n",
    "            tool = tools_by_name[tool_call[\"name\"]]\n",
    "            observation = tool.invoke(tool_call[\"args\"])\n",
    "            result.append(\n",
    "                ToolMessage(content=observation, tool_call_id=tool_call[\"id\"])\n",
    "            )\n",
    "            # </solution>\n",
    "        return {\"messages\": result}\n",
    "\n",
    "    # Exercise 4.3: Define conditional logic\n",
    "    # Hint: Check if the last message in state[\"messages\"] has `tool_calls`.\n",
    "    def should_continue(state: MessagesState) -> Literal[\"tool_node\", END]:\n",
    "        \"\"\"Decide if we should continue the loop or stop\"\"\"\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # <solution>\n",
    "        if last_message.tool_calls:\n",
    "            return \"tool_node\"\n",
    "        return END\n",
    "        # </solution>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba107d17",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "    # Exercise 4.4: Initialize graph and add nodes\n",
    "    # Hint: Use StateGraph(MessagesState). Add nodes using .add_node(\"name\", function).\n",
    "    # <solution>\n",
    "    agent_builder = StateGraph(MessagesState)\n",
    "    agent_builder.add_node(\"llm_call\", llm_call)\n",
    "    agent_builder.add_node(\"tool_node\", tool_node)\n",
    "    # </solution>\n",
    "\n",
    "    # Exercise 4.5: Add edges\n",
    "    # Hint: Use .add_edge(start, end) and .add_conditional_edges(source, condition, path_map).\n",
    "    # Connect START -> llm_call, then conditionally to tool_node or END, and tool_node back to llm_call.\n",
    "    # <solution>\n",
    "    agent_builder.add_edge(START, \"llm_call\")\n",
    "    agent_builder.add_conditional_edges(\"llm_call\", should_continue, [\"tool_node\", END])\n",
    "    agent_builder.add_edge(\"tool_node\", \"llm_call\")\n",
    "    # </solution>\n",
    "\n",
    "    return agent_builder.compile()\n",
    "\n",
    "\n",
    "# Exercise 4.6: Compile the graph\n",
    "# Hint: Call .compile() on the graph builder.\n",
    "# <solution>\n",
    "agent = build_agent(tools)\n",
    "# </solution>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf730a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Let's run this query\n",
    "math_query = \"Calculate ((144 / 12) * (25 + 75)) / ((10 * 10) / (500 / 5)) + ((81 / 9) * (121 / 11))\"\n",
    "\n",
    "# Exercise 4.7: Invoke the agent.\n",
    "# Hint: Initialize the conversation history with the query wrapped in a `HumanMessage` and use agent.invoke({\"messages\": messages})\n",
    "# <solution>\n",
    "messages = [HumanMessage(content=math_query)]\n",
    "response = agent.invoke({\"messages\": messages})\n",
    "# </solution>\n",
    "\n",
    "# show the message history\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4263eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.8: Create another agent, with the ability to search the web.\n",
    "#\n",
    "from ddgs import DDGS\n",
    "\n",
    "\n",
    "# Exercise 4.9: Use the above to create a search tool\n",
    "# <solution>\n",
    "@tool\n",
    "def web_search(query: str, max_results: int = 5):\n",
    "    \"\"\"Run a web search\"\"\"\n",
    "    return DDGS().text(query, max_results=max_results)\n",
    "\n",
    "\n",
    "# </solution>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"What is Altana?\"\n",
    "# Exercise 4.10: Build and invoke the agent.\n",
    "# <solution>\n",
    "agent = build_agent([web_search])\n",
    "messages = [HumanMessage(content=search_query)]\n",
    "response = agent.invoke({\"messages\": messages})\n",
    "# </solution>\n",
    "\n",
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d1046c",
   "metadata": {},
   "source": [
    "# Exercise 4.9: Compare to trajecotry of LangChain's ReAct implementation: (using `create_agent`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7aa2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "langchain_agent = create_agent(model=model, tools=[web_search])\n",
    "langchain_response = langchain_agent.invoke(HumanMessage(search_query))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
