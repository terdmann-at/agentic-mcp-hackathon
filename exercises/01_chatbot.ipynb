{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "459e7eaf",
   "metadata": {},
   "source": [
    "# Building a Chatbot\n",
    "\n",
    "First, we'll need to install a couple packages. If using serverless, add the packages `langchain` and `databricks-langchain` to the environment.\n",
    "If not using serverless run the below cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc69a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain databricks-langchain\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a3365",
   "metadata": {},
   "source": [
    "Today we'll be working with Databricks LLMs.\n",
    "Below we see an example for how to instantiate the model and for how\n",
    "to invoke it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36553c21",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain.messages import AIMessage, HumanMessage\n",
    "\n",
    "model = ChatDatabricks(endpoint=\"databricks-claude-sonnet-4-5\")\n",
    "\n",
    "response = model.invoke(\"hi\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5c1b1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Now it's your turn. Solve the exercises below.\n",
    "\n",
    "To test your chatbot, run this on the terminal:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b340dfb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Console Chatbot\n",
    "#\n",
    "# Build a simple chatbot using langchain and the Chat Completions API.\n",
    "#\n",
    "# Fill in the lines inside <solution></solution>.\n",
    "#\n",
    "\n",
    "def chat_shell():\n",
    "    # Initialize chat history\n",
    "    chat_history: list[HumanMessage | AIMessage] = []\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "\n",
    "        # Exercise 1.1: Add user message to the chat history.\n",
    "        # <solution>\n",
    "        chat_history.append(HumanMessage(content=user_input))\n",
    "        # </solution>\n",
    "\n",
    "        # Exercise 1.2: Invoke the model to get a response.\n",
    "        # Hint: Use `model.invoke(...)`\n",
    "        # <solution>\n",
    "        response = model.invoke(chat_history)\n",
    "        # </solution>\n",
    "        print(f\"AI: {response.content}\")\n",
    "\n",
    "        # Add AI message\n",
    "        chat_history.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761f66f7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Run the chatbot\n",
    "chat_shell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b2b6f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "638925fc",
   "metadata": {},
   "source": [
    "## Exercise 2 (Bonus): Streamlit Chatbot\n",
    "Use streamlit to build a simple chat interface.\n",
    "\n",
    "To test it, deploy the app.py to databricks apps using the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319adc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %mkdir streamlit_app_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7993fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile streamlit_app_01/requirements.txt\n",
    "# databricks-langchain\n",
    "# langchain\n",
    "# streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79cb13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile streamlit_app_01/app.yaml\n",
    "# command: [\"streamlit\", \"run\", \"app.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac20ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile streamlit_app_01/app.py\n",
    "import streamlit as st\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "st.title(\"Chatbot\")\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(\"user\" if isinstance(message, HumanMessage) else \"assistant\"):\n",
    "        st.markdown(message.content)\n",
    "\n",
    "if prompt := st.chat_input(\"What is up?\"):\n",
    "    st.session_state.messages.append(HumanMessage(content=prompt))\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        model = ChatDatabricks(endpoint=\"databricks-claude-sonnet-4-5\")\n",
    "        \n",
    "        # Exercise 2.1: Invoke the model with the message history\n",
    "        # Hint: input to invoke should be st.session_state.messages\n",
    "        # <solution>\n",
    "        response = model.invoke(st.session_state.messages)\n",
    "        # </solution>\n",
    "        \n",
    "        st.markdown(response.content)\n",
    "        \n",
    "        # Exercise 2.2: Append the response to the session state messages\n",
    "        # <solution>\n",
    "        st.session_state.messages.append(response)\n",
    "        # </solution>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
